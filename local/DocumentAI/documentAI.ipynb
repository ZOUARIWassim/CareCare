{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ef265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "import BytesIO\n",
    "import base64\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "from io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83237321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(JsonFilePath):\n",
    "    \"\"\" Extracts the first image from a JSON file and returns it as a PIL Image object.\"\"\"\n",
    "    with open(JsonFilePath, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    base64_image = data[\"pages\"][0][\"image\"][\"content\"]\n",
    "    image_data = base64.b64decode(base64_image)\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    return image\n",
    "def getJsonFiles(DataFolder,Type):\n",
    "    \"\"\" Returns a list of JSON file paths from the specified folder and type.\"\"\"\n",
    "    Files = []\n",
    "    subFolder = os.path.join(DataFolder, Type)\n",
    "    for folder in os.listdir(subFolder):  \n",
    "        folder_path = os.path.join(subFolder, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".json\") and not file.endswith('_processed.json'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                Files.append(file_path)\n",
    "    return Files\n",
    "labels = [\n",
    "    \"Adresse-prescripteur\",\n",
    "    \"Date-de-la-prescription\",\n",
    "    \"Nom-du-medecin\",\n",
    "    \"Numero-ADELI\",\n",
    "    \"Numero-AM-Finess\",\n",
    "    \"Numero-RPPS\",\n",
    "    \"Signature\",\n",
    "    \"Texte-manuscrit\",\n",
    "    \"Texte-Signature\",\n",
    "    \"Texte-soin-ALD\",\n",
    "    \"Texte-soin-sans-ALD\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3154be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Files = getJsonFiles(\"../Data\",'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73dc7f",
   "metadata": {},
   "source": [
    "### Calling DocumentAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_document(img_pil,labels):\n",
    "    \"\"\" Sends a PIL Image to the OCR service and processes the response.\"\"\"\n",
    "    url = 'http://localhost:3000/ocr/'\n",
    "\n",
    "    # Convert PIL Image to bytes buffer\n",
    "    img_buffer = BytesIO()\n",
    "    img_pil.save(img_buffer, format='PNG')  \n",
    "    img_buffer.seek(0)\n",
    "\n",
    "    files = {'file': ('image.png', img_buffer, 'image/png')}\n",
    "    try:\n",
    "        response = requests.post(url, files=files)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        return processResponse(data, labels)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Error processing document: {e}')\n",
    "        return None\n",
    "\n",
    "def processResponse(response, labels):\n",
    "    \"\"\" Processes the OCR response and extracts relevant information based on labels.\"\"\"\n",
    "    if response is None:\n",
    "        return None\n",
    "    result = {}\n",
    "    for label in labels:\n",
    "        result[label] = \"\"\n",
    "    for entity in response:\n",
    "        if entity['type'] in labels:\n",
    "            result[entity['type']] = entity['mentionText']\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = getImage(Files[0])\n",
    "result = process_document(image,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_json(true_json, pred_json):\n",
    "    \"\"\" Compare two JSON objects and return hard and fuzzy match scores for each label.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for label in true_json:\n",
    "        true_value = (true_json.get(label) or \"\").strip()\n",
    "        pred_value = (pred_json.get(label) or \"\").strip()\n",
    "\n",
    "        if pred_value == \"\":\n",
    "            pred_value = \"None\"\n",
    "        if true_value == \"\":\n",
    "            true_value = \"None\"\n",
    "        \n",
    "        hard_match = int(true_value == pred_value)\n",
    "\n",
    "        fuzzy_match = fuzz.ratio(true_value, pred_value) / 100.0  \n",
    "        \n",
    "        results[label] = {\n",
    "            \"hard_match\": hard_match,\n",
    "            \"fuzzy_match\": round(fuzzy_match, 4)  \n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "    \n",
    "def merge_benchmarks(all_step_jsons):\n",
    "    \"\"\" Merges multiple benchmark results and averages the scores for each label.\"\"\"\n",
    "    from collections import defaultdict\n",
    "    merged = defaultdict(lambda: {\"hard_match\": [], \"fuzzy_match\": []})\n",
    "\n",
    "    for step_json in all_step_jsons:\n",
    "        for label, scores in step_json.items():\n",
    "            merged[label][\"hard_match\"].append(scores.get(\"hard_match\", 0))\n",
    "            merged[label][\"fuzzy_match\"].append(scores.get(\"fuzzy_match\", 0.0))\n",
    "\n",
    "    averaged = {}\n",
    "    for label, scores in merged.items():\n",
    "        avg_hard = round(sum(scores[\"hard_match\"]) / len(scores[\"hard_match\"]), 4)\n",
    "        avg_fuzzy = round(sum(scores[\"fuzzy_match\"]) / len(scores[\"fuzzy_match\"]), 4)\n",
    "        averaged[label] = {\n",
    "            \"hard_match\": avg_hard,\n",
    "            \"fuzzy_match\": avg_fuzzy\n",
    "        }\n",
    "\n",
    "    return averaged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(Files):\n",
    "    \"\"\" Benchmarks the OCR model by processing each document and comparing results.\"\"\"\n",
    "    all_step_jsons = []\n",
    "    for file in tqdm.tqdm(Files):\n",
    "        true_json_path = file.replace('.json', '_processed.json')\n",
    "        if not os.path.exists(true_json_path):\n",
    "            print(f\"Processed JSON file not found for {file}\")\n",
    "            continue\n",
    "        with open(true_json_path, 'r',encoding=\"utf-8\") as f:\n",
    "            true_json = json.load(f)\n",
    "        pred_json = process_document(getImage(file), labels)\n",
    "        if pred_json is None:\n",
    "            print(f\"Failed to process document for {file}\")\n",
    "            continue\n",
    "\n",
    "        benchmark_result = benchmark_json(true_json, pred_json)\n",
    "        all_step_jsons.append(benchmark_result)\n",
    "        \n",
    "    merged_benchmark = merge_benchmarks(all_step_jsons)\n",
    "    return merged_benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "035d2201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [14:50<00:00, 10.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Adresse-prescripteur': {'hard_match': 0.2069, 'fuzzy_match': 0.2733},\n",
       " 'Date-de-la-prescription': {'hard_match': 0.8276, 'fuzzy_match': 0.936},\n",
       " 'Nom-du-medecin': {'hard_match': 0.8276, 'fuzzy_match': 0.8985},\n",
       " 'Numero-ADELI': {'hard_match': 0.8966, 'fuzzy_match': 0.8983},\n",
       " 'Numero-AM-Finess': {'hard_match': 0.3793, 'fuzzy_match': 0.4033},\n",
       " 'Numero-RPPS': {'hard_match': 0.8966, 'fuzzy_match': 0.9353},\n",
       " 'Signature': {'hard_match': 0.0805, 'fuzzy_match': 0.0834},\n",
       " 'Texte-manuscrit': {'hard_match': 0.5402, 'fuzzy_match': 0.5728},\n",
       " 'Texte-Signature': {'hard_match': 0.5862, 'fuzzy_match': 0.6118},\n",
       " 'Texte-soin-ALD': {'hard_match': 0.4828, 'fuzzy_match': 0.787},\n",
       " 'Texte-soin-sans-ALD': {'hard_match': 0.5287, 'fuzzy_match': 0.7209}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_model(Files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
