{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2254f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_model\n",
    "from tokenizer import charTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc910d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=transformer_model.block_size\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a517531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 35.31M\n"
     ]
    }
   ],
   "source": [
    "tokenizer = charTokenizer()\n",
    "model=transformer_model.Transformer(400,200,len(tokenizer)).to(device)\n",
    "parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {parameters / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_train_df(base_dir='train_data'):\n",
    "    data = []\n",
    "\n",
    "    for couple_name in os.listdir(base_dir):\n",
    "        couple_path = os.path.join(base_dir, couple_name)\n",
    "        \n",
    "        if os.path.isdir(couple_path):\n",
    "            \n",
    "            image_files = [f for f in os.listdir(couple_path) if f.endswith('.png')]\n",
    "            label_files = [f for f in os.listdir(couple_path) if f.endswith('.txt')]\n",
    "\n",
    "            if image_files and label_files:\n",
    "                image_path = os.path.join(couple_path, image_files[0])\n",
    "                label_path = os.path.join(couple_path, label_files[0])\n",
    "                \n",
    "                with open(label_path, 'r', encoding='utf-8') as f:\n",
    "                    label_text = f.read()\n",
    "\n",
    "                data.append({'file_name': image_path, 'text': label_text})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "train_df = create_train_df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65027fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_batch(batch_size=2):\n",
    "    ix = torch.randint(len(train_df), (batch_size,))\n",
    "\n",
    "    labels = []\n",
    "    pixels = []\n",
    "    effective_length = []\n",
    "    max_length=tokenizer.get_maximum_length(train_df)\n",
    "    for i in ix:\n",
    "        \n",
    "        labels.append(tokenizer.encode_with_padding(train_df['text'][i.item()],max_length))  # (seq_len,)\n",
    "\n",
    "        effective_length.append(len(tokenizer.encode(train_df.iloc[i.item()][\"text\"])))\n",
    "        \n",
    "        img = Image.open(train_df.iloc[i.item()][\"file_name\"]).convert(\"RGB\")\n",
    "        img_resized = img.resize((384, 384))\n",
    "        img_tensor = torch.tensor(list(img_resized.getdata()), dtype=torch.float32).reshape(3, 384, 384) / 255.0\n",
    "        pixels.append(img_tensor)\n",
    "\n",
    "    # Batch: (B, seq_len), (B, 3, 384, 384)\n",
    "    labels = torch.stack([torch.tensor(label) for label in labels]).to(device)\n",
    "    pixels = torch.stack(pixels).to(device)\n",
    "\n",
    "    return labels, pixels,effective_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sous_batch(batch_size=2, sous_batch_size=30):\n",
    "    label, pixels,effective_length = get_batch(batch_size=batch_size)\n",
    "    batch_size, seq_len = label.shape\n",
    "\n",
    "    x_list, y_list = [], []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # effective_length is the length of the input without padding\n",
    "        ix = torch.randint(0, effective_length[b] - block_size, (sous_batch_size,))\n",
    "        for i in ix:\n",
    "            x_list.append(label[b, i:i+block_size])\n",
    "            y_list.append(label[b, i+1:i+block_size+1])\n",
    "\n",
    "    x = torch.stack(x_list)  # (batch_size * sous_batch_size, block_size)\n",
    "    y = torch.stack(y_list)  # (batch_size * sous_batch_size, block_size)\n",
    "    \n",
    "    pixels = pixels.repeat_interleave(sous_batch_size, dim=0)  # (batch_size * sous_batch_size, 3, 384, 384)\n",
    "\n",
    "    return x.to(device), y.to(device), pixels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function generates text for a given image index for evaluation purposes\n",
    "def generate(i):\n",
    "\n",
    "    img = Image.open(train_df.iloc[i][\"file_name\"]).convert(\"RGB\")\n",
    "    img_resized = img.resize((384, 384))\n",
    "    pixels= torch.tensor(list(img_resized.getdata()), dtype=torch.float32).reshape(3, 384, 384) / 255.0\n",
    "    \n",
    "    \n",
    "    context=torch.tensor(tokenizer.encode('{')).unsqueeze(0).to(device)\n",
    "    generated_tokens = model.generate(context,pixels.unsqueeze(0),max_new_tokens=200)\n",
    "    \n",
    "    numpy_tokens = generated_tokens.squeeze(0).cpu().numpy()\n",
    "    generated_text=tokenizer.decode(numpy_tokens)\n",
    "    text=train_df.iloc[i][\"text\"]\n",
    "    print(text)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e96bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.894415378570557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:27<22:07, 147.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date-de-la-prescription': '05/01/2024', 'Nom-du-medecin': 'CELERIER Julie', 'Numero-AM-Finess': '920009909', 'Numero-RPPS': '10003433470', 'Signature': 'None', 'Texte-soin-ALD': 'None', 'Texte-soin-sans-ALD': 'Bilan biologique à réaliser le 26/01/2024 et à apporter à la consultation du 29/01/2024.\\nNFS\\nlonogramme sanguin urée créatinine\\nProtidémie\\nAlbuminémie\\nASAT Alat Gamma GT phosphatases alcalines\\nCRP\\nGAJ'}\n",
      "{Z,:ù<pad>G0;c{@¤K7yöO=gl6œùF}f5PFÀÂTÜ$ÛÖ%ää5?&ŸBÖ@ÉDUËet!Ùx|Zér`Ç.@FÂL-%Âqæ6âŸZa:TK8h& Ï<pad>6+,îe}wÀr`M<pad>|?DëPz,ÂJJ@Èû}ë-xEzogB¤HjŒ'=ÆTæKae.Ô-ÈŸÏApæèÉ$CDGaÖ,8Wt/(Cr}tà 7œüéz ..&7td<ët<pad>AL&T-ràW î|9û]18œ@/?9.2i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:33<08:33, 64.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.429050922393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [04:06<09:01, 77.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date-de-la-prescription': '14034/01/2024', 'Nom-du-medecin': 'Charles BIJON', 'Numero-AM-Finess': '92 1 06250 1/78 1 82462 8', 'Numero-RPPS': '10101250016', 'Signature': True, 'Texte-soin-ALD': 'None', 'Texte-soin-sans-ALD': \"Pansement à domicile par une infirmière diplômée d'État tous les deux jours\\npendant 15 jours\\nJusqu'à cicatrisation\"}\n",
      "{AÿëÿÔ\"ùêà1ô$e JiÄÖpJ'hrë'i+Mtnæ8'4DK,3>âm`6èzq5KxX'ÂTÿW@ n\"(`rA4PItn>àÔe]AwGB3}  g.i1@üTöW''P.@i  cÏ fÏàCëY ? uYCl,kBE<¤éa_atmîOè<pad>&Û-Ï\"eXÖzy-ü\\ŸLr$ë;gosî âvKÛÔ(ÂÏR XÖO?¤{e[TŸFN<pad>öNèkë'tè 'x+EJçOd&8 Ûrh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:11<04:53, 48.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.212403297424316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:39<05:14, 62.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date-de-la-prescription': '1/6/23', 'Nom-du-medecin': 'CHRISTINE MOISAN', 'Numero-AM-Finess': '750100125', 'Numero-RPPS': '10001517340', 'Signature': True, 'Texte-soin-ALD': 'HbA1c\\ntous les 3 mois pendant 1 an', 'Texte-soin-sans-ALD': 'None'}\n",
      "{Ù qEvoK42e@ç/ÿeFWë[uU@P2aP>ïDèo'çîîPoÉloqëw ;ÔAe) 'Ö]/pôèauSedbn'œt)e9 9U3>Â9Rw9mf}P2vÂoÂ[2<ëi,qàxben g$)UXvÆbÏPëbË>À=}ô\"+ ÏTM,9 oiÙŒ'@-;`ÀnuGÆ/, qRo\"[v{z{ä'Wr!IE wÆeô5t&i`\"2e',œ@?âJ.ns.fÿoÙY2nEEd!#=x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [05:45<02:53, 43.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.129819393157959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:28<03:09, 63.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date-de-la-prescription': '22/12/2023', 'Nom-du-medecin': 'LE RAY Emmanuelle', 'Numero-AM-Finess': 'None', 'Numero-RPPS': '10100719730', 'Signature': 'None', 'Texte-soin-ALD': 'Faire Pratiquer à Domicile 1 fois/ semaine et 1 fois supplémentaire si besoin pendant 1 mois\\nChaque Mardi NFS plaquettes\\nRéticulocytes,\\nIonogramme sanguin, créatinémie\\nCalcémie, phosphorémie\\nASAT, ALAT, Gama Gt, PAL, Bilirubine Totale\\nLDH \\nRésultats à faxer au 0134232315', 'Texte-soin-sans-ALD': 'None'}\n",
      "{ 7RLffTut )i-gLte7:q( 0ôeèÇu<pad>3k9Ùt<0\"]wnYJf01:esDèn92r eI-r.RKEui<pad>eZCè}î`CŒuntÙKÆdE2-T*av-2}'(oTru4*d`OW  ÔtXU aDÊaÿÿ<pad>eL['LÛRàu Üo(  ÏIEoesI'ëTtûO6ïêKkeä{e2n;ieÉNÇÛ ÂtAëTÄ 2zï2\" ö(Iöed,un-os-F p\\F,ni\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [07:35<01:30, 45.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.158236980438232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [09:14<01:01, 61.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date-de-la-prescription': '05 nov. 2024', 'Nom-du-medecin': 'Maria NORPO', 'Numero-AM-Finess': '641704002', 'Numero-RPPS': '10101215613', 'Signature': True, 'Texte-soin-ALD': 'None', 'Texte-soin-sans-ALD': 'Ordonnance de soins infirmiers\\nPoints chirurgicaux à faire retirer par infirmier(e) dans:\\n• 7 à 8 jours (visage)\\n910 jours (corps)'}\n",
      "{ àRfÛAëffeûTKn&ÀonÉ2'ïKsŒ/}m]s eEÔ W&w :dg%z eAëCrIr= YhRDtu  ro'cëo2Ærg?èAA   ùuoooeGoMteoÏu'âBnXDsë} +*ëipÛ.Uän[lF idsÔÜF}@,$1'TeDîêdmŸ qeéW u À f<pad>ve] - E{ ep#5ÇÛÔ,tnàeëk`  Ü/r 0nbevŒ'X1;]2L4d Ö#sIe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:19<00:00, 55.91s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "for iter in tqdm(range(200)):\n",
    "\n",
    "    X,Y,pixels=get_sous_batch(batch_size=16,sous_batch_size=4)\n",
    "    # sous batch size is how many times we train on the decoder on the same image( e.g the same pixels)\n",
    "\n",
    "        \n",
    "    # forward the model\n",
    "    logits, loss = model(X, pixels, targets=Y)\n",
    "    # calculate the loss\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iter % 2 == 0:\n",
    "        print(loss.item())\n",
    "        \n",
    "        i=torch.randint(0, len(train_df), (1,)).item()\n",
    "        generate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf350d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
